name: llama
channels:
  - defaults
dependencies:
  - _libgcc_mutex=0.1=main
  - _openmp_mutex=5.1=1_gnu
  - ca-certificates=2023.08.22=h06a4308_0
  - cudatoolkit=11.8.0=h6a678d5_0
  - ld_impl_linux-64=2.38=h1181459_1
  - libffi=3.4.4=h6a678d5_0
  - libgcc-ng=11.2.0=h1234567_1
  - libgomp=11.2.0=h1234567_1
  - libstdcxx-ng=11.2.0=h1234567_1
  - ncurses=6.4=h6a678d5_0
  - openssl=3.0.12=h7f8727e_0
  - pip=23.3.1=py39h06a4308_0
  - python=3.9.18=h955ad1f_0
  - readline=8.2=h5eee18b_0
  - setuptools=68.0.0=py39h06a4308_0
  - sqlite=3.41.2=h5eee18b_0
  - tk=8.6.12=h1ccaba5_0
  - wheel=0.41.2=py39h06a4308_0
  - xz=5.4.5=h5eee18b_0
  - zlib=1.2.13=h5eee18b_0
  - pip:
      - accelerate==0.25.0
      - aiohttp==3.9.1
      - aiosignal==1.3.1
      - annotated-types==0.6.0
      - anyio==4.3.0
      - appdirs==1.4.4
      - asttokens==2.4.1
      - async-timeout==4.0.3
      - attrs==23.1.0
      - bitsandbytes==0.39.1
      - black==23.11.0
      - brotli==1.1.0
      - certifi==2023.11.17
      - charset-normalizer==3.3.2
      - click==8.1.7
      - cmake==3.27.9
      - contourpy==1.2.1
      - cycler==0.12.1
      - datasets==2.15.0
      - decorator==5.1.1
      - dill==0.3.7
      - distro==1.9.0
      - exceptiongroup==1.2.0
      - executing==2.0.1
      - filelock==3.13.1
      - fire==0.5.0
      - fonttools==4.50.0
      - frozenlist==1.4.0
      - fsspec==2023.10.0
      - h11==0.14.0
      - httpcore==1.0.5
      - httpx==0.27.0
      - huggingface-hub==0.19.4
      - idna==3.6
      - importlib-resources==6.4.0
      - inflate64==1.0.0
      - ipython==8.18.1
      - jedi==0.19.1
      - jinja2==3.1.2
      - joblib==1.3.2
      - kiwisolver==1.4.5
      - lit==17.0.6
      - loralib==0.1.2
      - markupsafe==2.1.3
      - matplotlib==3.8.4
      - matplotlib-inline==0.1.6
      - mpmath==1.3.0
      - multidict==6.0.4
      - multiprocess==0.70.15
      - multivolumefile==0.2.3
      - mypy-extensions==1.0.0
      - networkx==3.2.1
      - nltk==3.8.1
      - numpy==1.26.2
      - nvidia-cublas-cu12==12.1.3.1
      - nvidia-cuda-cupti-cu12==12.1.105
      - nvidia-cuda-nvrtc-cu12==12.1.105
      - nvidia-cuda-runtime-cu12==12.1.105
      - nvidia-cudnn-cu12==8.9.2.26
      - nvidia-cufft-cu12==11.0.2.54
      - nvidia-curand-cu12==10.3.2.106
      - nvidia-cusolver-cu12==11.4.5.107
      - nvidia-cusparse-cu12==12.1.0.106
      - nvidia-nccl-cu12==2.18.1
      - nvidia-nvjitlink-cu12==12.3.101
      - nvidia-nvtx-cu12==12.1.105
      - openai==0.28.0
      - packaging==23.2
      - pandas==2.1.4
      - parso==0.8.3
      - pathspec==0.11.2
      - peft==0.7.1.dev0
      - pexpect==4.9.0
      - pillow==10.3.0
      - platformdirs==4.1.0
      - prompt-toolkit==3.0.41
      - protobuf==4.25.1
      - psutil==5.9.6
      - ptyprocess==0.7.0
      - pure-eval==0.2.2
      - py3nvml==0.2.7
      - py7zr==0.20.8
      - pyarrow==14.0.1
      - pyarrow-hotfix==0.6
      - pybcj==1.0.2
      - pycryptodomex==3.19.0
      - pydantic==2.6.4
      - pydantic-core==2.16.3
      - pygments==2.17.2
      - pyparsing==3.1.2
      - pyppmd==1.1.0
      - python-dateutil==2.8.2
      - pytz==2023.3.post1
      - pyyaml==6.0.1
      - pyzstd==0.15.9
      - regex==2023.10.3
      - requests==2.31.0
      - safetensors==0.4.1
      - scipy==1.11.4
      - sentencepiece==0.1.99
      - six==1.16.0
      - sniffio==1.3.1
      - stack-data==0.6.3
      - sympy==1.12
      - termcolor==2.4.0
      - texttable==1.7.0
      - tokenize-rt==5.2.0
      - tokenizers==0.15.0
      - tomli==2.0.1
      - torch==2.0.1+cu118
      - tqdm==4.66.1
      - traitlets==5.14.0
      - transformers==4.35.2
      - triton==2.0.0
      - typing-extensions==4.8.0
      - tzdata==2023.3
      - urllib3==2.1.0
      - wcwidth==0.2.12
      - xmltodict==0.13.0
      - xxhash==3.4.1
      - yarl==1.9.4
      - zipp==3.18.1
prefix: /home/sunqi/miniconda3/envs/llama
